{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of movie IDs from the movieDB dataset\n",
    "# Use todays_date formatted as mm_dd_YYYY\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import jsonlines\n",
    "\n",
    "TODAY_DATE = datetime.today().strftime(\"%m_%d_%Y\")\n",
    "TMDB_HEADERS = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJiNmIwYzVkYTQ3OWM5OTZmNDVhYmZhODBhYjk2MDYwNyIsInN1YiI6IjYwMjJkNzljYzBhZTM2MDAzZjU2MDk1NyIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.9P7cdBGlQBBY5VITB8vVsZ9-kYJ7xsz-Y2qqKGeEDc0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store movie ID files\n",
    "movie_ids_directory = \"./movie_ids/\"\n",
    "os.makedirs(movie_ids_directory, exist_ok=True)\n",
    "\n",
    "# File path for storing movie IDs\n",
    "old_movie_ids_filenames: list[str] = os.listdir(movie_ids_directory)\n",
    "latest_movie_ids_path: str = os.path.join(movie_ids_directory, sorted(old_movie_ids_filenames)[-1])\n",
    "\n",
    "# Check if the file exists and is older than 14 days\n",
    "if not os.path.exists(latest_movie_ids_path) or (\n",
    "    datetime.now() - datetime.fromtimestamp(os.path.getmtime(latest_movie_ids_path))\n",
    ") > timedelta(days=14):\n",
    "    # Download movie IDs\n",
    "    movie_ids_url = f\"http://files.tmdb.org/p/exports/movie_ids_{TODAY_DATE}.json.gz\"\n",
    "    latest_movie_ids_path: str = os.path.join(movie_ids_directory, f\"movie_ids_{TODAY_DATE}.json\")\n",
    "    r = requests.get(movie_ids_url)\n",
    "\n",
    "    # Save the gzipped file\n",
    "    with open(f\"movie_ids_{TODAY_DATE}.json.gz\", \"wb\") as code:\n",
    "        code.write(r.content)\n",
    "\n",
    "    # Unzip the file and save the JSON\n",
    "    with gzip.open(f\"movie_ids_{TODAY_DATE}.json.gz\", \"rb\") as f_in:\n",
    "        with open(latest_movie_ids_path, \"wb\") as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    # Remove the gz file\n",
    "    os.remove(f\"movie_ids_{TODAY_DATE}.json.gz\")\n",
    "    print(\"Movie IDs updated.\")\n",
    "    # if updated, get the difference in movie ids between the old and new files\n",
    "    # load the latest movie ids\n",
    "    with jsonlines.open(latest_movie_ids_path) as reader:\n",
    "        latest_movie_ids_set: set[str] = {movie[\"id\"] for movie in reader}\n",
    "    # load the old movie ids\n",
    "    with jsonlines.open(f\"./movie_ids/{sorted(old_movie_ids_filenames)[-1]}\") as reader:\n",
    "        old_movie_ids_set: set[str] = {movie[\"id\"] for movie in reader}\n",
    "    new_movie_count: int = len(latest_movie_ids_set) - len(old_movie_ids_set)\n",
    "    print(f\"{new_movie_count} new movie IDs found.\")\n",
    "    del latest_movie_ids_set, old_movie_ids_set, new_movie_count\n",
    "else:\n",
    "    print(\"Movie IDs are up to date.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small analysis using pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(latest_movie_ids_path, lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_movies_to_keep = 10_000\n",
    "df_filtered = df.sort_values(by=\"popularity\", ascending=False).head(num_of_movies_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.themoviedb.org/3/authentication\"\n",
    "\n",
    "response = requests.get(url, headers=TMDB_HEADERS)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every movie ID in the filtered dataframe, get the 20 main actors, the director, the writer, the cinematographer and the composer (if they exist), their popularity, their id, their known_for_department (for cast list), their name and their job (for crew list)\n",
    "\n",
    "movies = [\n",
    "    {\"id\": x.id, \"title\": x.original_title, \"popularity\": x.popularity}\n",
    "    for x in df_filtered.itertuples()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def fetch_movie_release_date(movie) -> None:\n",
    "    \"\"\"\n",
    "    Fretches the release date for a movie from the TMDB API and adds it to the movie dict.\n",
    "    Endpoint: https://api.themoviedb.org/3/movie/{movie_id}\n",
    "\n",
    "    Args:\n",
    "        movie (dict): A movie dict from the movies list\n",
    "    \"\"\"\n",
    "    # test if not already queried the info\n",
    "    if \"release_date\" in movie:\n",
    "        return\n",
    "\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{movie['id']}\"\n",
    "\n",
    "    response = requests.get(url, headers=TMDB_HEADERS)\n",
    "\n",
    "    # if status is 429, wait for 10 seconds and try again. If fails again, exit\n",
    "    if response.status_code == 429:\n",
    "        time.sleep(10)\n",
    "        response = requests.get(url, headers=TMDB_HEADERS)\n",
    "        if response.status_code == 429:\n",
    "            print(\"Too many requests. Exiting.\")\n",
    "            sys.exit()\n",
    "\n",
    "    # test if status is 200\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error for movie {movie['id']}: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    response_json = response.json()\n",
    "    movie[\"release_date\"] = response_json[\"release_date\"]\n",
    "\n",
    "\n",
    "def fetch_movie_credits(movie) -> None:\n",
    "    \"\"\"\n",
    "    Fetches the cast and crew for a movie from the TMDB API and adds them to the movie dict.\n",
    "    Credits endpoint: https://api.themoviedb.org/3/movie/{movie_id}/credits\n",
    "\n",
    "    Args:\n",
    "        movie (dict): A movie dict from the movies list\n",
    "    \"\"\"\n",
    "    # test if not already queried the info\n",
    "    if \"cast\" in movie and \"crew\" in movie:\n",
    "        return\n",
    "\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{movie['id']}/credits\"\n",
    "\n",
    "    response = requests.get(url, headers=TMDB_HEADERS)\n",
    "\n",
    "    # if status is 429, wait for 10 seconds and try again. If fails again, exit\n",
    "    if response.status_code == 429:\n",
    "        time.sleep(10)\n",
    "        response = requests.get(url, headers=TMDB_HEADERS)\n",
    "        if response.status_code == 429:\n",
    "            print(\"Too many requests. Exiting.\")\n",
    "            sys.exit()\n",
    "\n",
    "    # test if status is 200\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error for movie {movie['id']}: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    response_json = response.json()\n",
    "    cast = response_json[\"cast\"]\n",
    "    crew = response_json[\"crew\"]\n",
    "\n",
    "    # select attributes for cast, only 20 first actors\n",
    "    movie[\"cast\"] = [\n",
    "        {\n",
    "            \"id\": x[\"id\"],\n",
    "            \"name\": x[\"name\"],\n",
    "            \"popularity\": x[\"popularity\"],\n",
    "            \"known_for_department\": x[\"known_for_department\"],\n",
    "        }\n",
    "        for x in cast[:20]\n",
    "    ]\n",
    "\n",
    "    # select attributes for crew\n",
    "    movie[\"crew\"] = [\n",
    "        {\n",
    "            \"id\": x[\"id\"],\n",
    "            \"name\": x[\"name\"],\n",
    "            \"popularity\": x[\"popularity\"],\n",
    "            \"known_for_department\": x[\"known_for_department\"],\n",
    "            \"job\": x[\"job\"],\n",
    "        }\n",
    "        for x in crew\n",
    "        if x[\"job\"] in [\n",
    "            \"Director\",\n",
    "            \"Writer\",\n",
    "            \"Director of Photography\",\n",
    "            \"Original Music Composer\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_movie_dict(movie) -> None:\n",
    "    \"\"\"\n",
    "    Creates a movie dict with the attributes we want to keep.\n",
    "\n",
    "    Args:\n",
    "        movie (dict): A movie dict from the movies list\n",
    "\n",
    "    Returns:\n",
    "        dict: A movie dict with the attributes we want to keep\n",
    "    \"\"\"\n",
    "    fetch_movie_release_date(movie)\n",
    "    fetch_movie_credits(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Separate movies into 5 parts\n",
    "num_threads = 20\n",
    "chunk_size = len(movies) // num_threads\n",
    "movie_chunks = [movies[i:i + chunk_size] for i in range(0, len(movies), chunk_size)]\n",
    "\n",
    "# Function to process a chunk of movies\n",
    "def process_chunk(chunk):\n",
    "    for movie in tqdm(chunk):\n",
    "        create_movie_dict(movie)\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Submit the chunks for processing\n",
    "    futures = [executor.submit(process_chunk, chunk) for chunk in movie_chunks]\n",
    "\n",
    "    # Wait for all threads to finish\n",
    "    concurrent.futures.wait(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes about 3minutes for 10k movies on 20 threads (if no rate limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge movie_chunks into a list, with one item per movie\n",
    "movies_dicts = [movie for chunk in movie_chunks for movie in chunk]\n",
    "len(movies_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the movies list as a json lines file\n",
    "with jsonlines.open(\"movies.jsonl\", mode=\"w\") as writer:\n",
    "    writer.write_all(movies_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json lines file\n",
    "with jsonlines.open(\"movies.jsonl\") as reader:\n",
    "    movies_dicts = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert all the movies into the Cypher database.\n",
    "# Should contain the following nodes:\n",
    "# - Movie (id, title, popularity)\n",
    "# - Person (id, name, popularity, known_for_department)\n",
    "\n",
    "# Should contain the following relationships:\n",
    "# - FEATURED_IN (Person)-[:FEATURED_IN]->(Movie) (whether as cast or crew)\n",
    "\n",
    "from neo4j_utils import GraphDbConnector\n",
    "\n",
    "graph = GraphDbConnector(\"bolt://localhost:7687\", \"neo4j\", \"password\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create constraints\n",
    "try:\n",
    "    graph.initialize_database()\n",
    "except Exception:\n",
    "    print(\"DB Already initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert all the movies and people into the database\n",
    "\n",
    "# create a dictionary of all the people in the movies\n",
    "people = {}\n",
    "for movie in movies_dicts:\n",
    "    for person in movie[\"cast\"] + movie[\"crew\"]:\n",
    "        if person[\"id\"] not in people:\n",
    "            people[person[\"id\"]] = person\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in tqdm(people.values()): # 100k people, about 20 minutes\n",
    "    graph.insert_person(person[\"id\"], person[\"name\"], person[\"popularity\"])\n",
    "\n",
    "for movie in tqdm(movies_dicts):  # 20 secs for 10k movies\n",
    "    realease_year = movie[\"release_date\"].split(\"-\")[0]\n",
    "    graph.insert_movie(\n",
    "        movie[\"id\"],\n",
    "        movie[\"title\"],\n",
    "        movie[\"popularity\"],\n",
    "        movie[\"release_date\"].split(\"-\")[0],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert all the relationships into the database\n",
    "\n",
    "# Parralelize code:\n",
    "# Separate movies into 20 parts, takes about 10/20min\n",
    "\n",
    "num_threads = 20\n",
    "\n",
    "chunk_size = len(movies_dicts) // num_threads\n",
    "\n",
    "movie_chunks = [movies_dicts[i:i + chunk_size] for i in range(0, len(movies_dicts), chunk_size)]\n",
    "\n",
    "# Function to process a chunk of movies\n",
    "def process_chunk(chunk):\n",
    "    for movie in tqdm(chunk):\n",
    "        for person in movie[\"cast\"]:\n",
    "            graph.insert_person_to_movie(\n",
    "                person[\"id\"], movie[\"id\"], person[\"known_for_department\"], \"actor\"\n",
    "            )\n",
    "        for person in movie[\"crew\"]:\n",
    "            graph.insert_person_to_movie(\n",
    "                person[\"id\"], movie[\"id\"], person[\"known_for_department\"], person[\"job\"]\n",
    "            )\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Submit the chunks for processing\n",
    "    futures = [executor.submit(process_chunk, chunk) for chunk in movie_chunks]\n",
    "\n",
    "    # Wait for all threads to finish\n",
    "    concurrent.futures.wait(futures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cine2nerdle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
